<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hugging Face Text Generation Demo</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 2rem;
    }
    #output {
      white-space: pre-wrap;
      background: #f9f9f9;
      padding: 1rem;
      border: 1px solid #ccc;
      margin-top: 1rem;
    }
  </style>
  <script type="importmap">
    {
      "imports": {
        "onnxruntime-common": "https://esm.sh/onnxruntime-common",
        "onnxruntime-web": "https://esm.sh/onnxruntime-web"
      }
    }
  </script>
</head>
<body>
  <h1>Hugging Face Transformers Demo</h1>
  <p id="modelStatus">Loading model...</p>
  <button id="runBtn" disabled>Generate Text</button>
  <div id="output">Output will appear here...</div>
  <script type="module">
    // First, import onnxruntime-web to configure the WASM path.
    import * as ort from 'onnxruntime-web';
    // Set the path to the onnxruntime-web WASM binaries.
    ort.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/";

    // Then import the transformers pipeline and TextStreamer.
    import { pipeline, TextStreamer } from './transformers.min.js';

    const modelStatus = document.getElementById('modelStatus');
    const runBtn = document.getElementById('runBtn');

    // Fallback to "cpu" when WebGPU is not available (Safari currently lacks WebGPU)
    const device = navigator.gpu ? "webgpu" : "cpu";

    // Initialize the text generation pipeline.
    const generator = await pipeline(
      "text-generation",
      "onnx-community/Qwen2.5-0.5B-Instruct",
      { dtype: "q4", device }
    );

    modelStatus.textContent = 'Model loaded!';
    runBtn.disabled = false;

    async function runGeneration() {
      const messages = [
        { role: "system", content: "You are a helpful assistant that tells jokes. You MUST only tell one joke and then stop." },
        { role: "user", content: "Tell me one funny joke and then stop." }
      ];

      const outputElement = document.getElementById('output');
      outputElement.textContent = '';

      const streamer = new TextStreamer(generator.tokenizer, {
        skip_prompt: true,
        callback_function: (text) => {
          let generatedText = text;
          const stopPhrases = ["That's all!", "End of joke.", "\n\n"];
          for (const phrase of stopPhrases) {
            const index = generatedText.indexOf(phrase);
            if (index !== -1) {
              generatedText = generatedText.substring(0, index + phrase.length);
              break;
            }
          }
          outputElement.textContent += generatedText;
        }
      });

      const result = await generator(messages, {
        max_new_tokens: 25,
        do_sample: true,
        temperature: 0.7,
        top_k: 50,
        top_p: 0.95,
        typical_p: 0.95,
        length_penalty: 1.0,
        repetition_penalty: 1.5,
        no_repeat_ngram_size: 3,
        num_beams: 2,
        num_return_sequences: 1,
        stop: [".", "!", "?"],
        streamer
      });

      console.log(result[0].generated_text.at(-1).content);
    }

    document.getElementById('runBtn').addEventListener('click', runGeneration);
  </script>
</body>
</html>
